{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In the entire project, I have divided the given training dataset into train and test splits. 80 percent data is for training and 20 percent for testing. The reason I did this is because I did not have the probabilites for the test dataset so I would not have been able to find accuracy in that case. Also dividing the training dataset into two helps in reducing the total execution time."
      ],
      "metadata": {
        "id": "PWMalQDcEwVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have added comments wherever I felt it was required."
      ],
      "metadata": {
        "id": "kBJCVH5GMd7n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-06T14:14:14.562189Z",
          "iopub.status.busy": "2024-11-06T14:14:14.561098Z",
          "iopub.status.idle": "2024-11-06T14:16:23.675414Z",
          "shell.execute_reply": "2024-11-06T14:16:23.674308Z",
          "shell.execute_reply.started": "2024-11-06T14:14:14.562146Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn8gyCdc6Mst",
        "outputId": "8e94e1ef-b9a8-4297-fca9-1cfba6250482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12316/12316 [50:04<00:00,  4.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to predictions1.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4916\n",
            "F1 Score: 0.3296\n",
            "Precision: 0.2458\n",
            "Recall: 0.5000\n"
          ]
        }
      ],
      "source": [
        "#Q.1\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"/content/images_training_rev1.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/images_training_rev1\")   #extraction of images\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"/content/training_solutions_rev1_updated.csv\")  #Reads the CSV file containing galaxy classification labels and probabilities for training images into a Pandas DataFrame.\n",
        "\n",
        "\n",
        "train_sp, test_sp = train_test_split(data, test_size=0.2, random_state=42) #80% is for training\n",
        "\n",
        "#already existing resnet-50 is used in this question\n",
        "model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
        "model.fc = nn.Linear(model.fc.in_features, 37)  #Replaces the fully connected layer (model.fc) to output 37 classes (one for each galaxy morphology category).\n",
        "model.eval()\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  #Resizes images to 224x224 (required for ResNet-50).\n",
        "    transforms.ToTensor(),   #Converts images to PyTorch tensors.\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  #Normalizes pixel values using the ImageNet mean and standard deviation.\n",
        "])\n",
        "\n",
        "image_dir = \"/content/images_training_rev1/\" #here are my extracted images\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  #uses GPU if available\n",
        "model.to(device)  #Moves the model to the selected device.\n",
        "\n",
        "all_probabilities = []  #an empty list to store probabilites\n",
        "#tqdm displays a progress bar that updates dynamically as a loop runs.\n",
        "for galaxy_id in tqdm(test_sp[\"GalaxyID\"]):   #Iterates over the GalaxyID column in the test split (test_sp).\n",
        "    image_path = os.path.join(image_dir, f\"{galaxy_id}.jpg\")  #Constructs the image path for each GalaxyID.\n",
        "    if not os.path.exists(image_path):  #If the image doesn't exist, prints a warning and skips it.\n",
        "        print(f\"Image not found: {image_path}\")\n",
        "        continue\n",
        "\n",
        "    image = Image.open(image_path).convert(\"RGB\")  #Opens the image and converts it to RGB format.\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():  #Disables gradient calculation for inference (saves memory and computation).\n",
        "        output = model(image) #Passes the image through the model to get raw output logits.\n",
        "        probabilities = torch.softmax(output, dim=1).cpu().numpy().flatten()  #Applies the softmax function to convert logits into probabilities for each class.\n",
        "\n",
        "    all_probabilities.append(probabilities)\n",
        "\n",
        "\n",
        "class_labels = [f'Class{i+1}' for i in range(37)]  # class_labels: Creates a list of column names (Class1, Class2, ..., Class37).\n",
        "predictions_df = pd.DataFrame(all_probabilities, columns=class_labels) #Converts all_probabilities to a Pandas DataFrame with class labels as column names.\n",
        "predictions_df.insert(0, 'GalaxyID', test_sp['GalaxyID'].values) #Inserts the GalaxyID column at the start of the DataFrame.\n",
        "predictions_df.to_csv(\"predictions1.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to predictions1.csv\")  #predictions are saved in predictions1.csv\n",
        "#finding accuracy\n",
        "#here i have converted the probabailites either to 0 or 1. if probability is >0.5, it is converted to 1 and otherwise converted to 0\n",
        "missing_labels = [label for label in class_labels if label not in test_sp.columns] #Checks if any expected class labels are missing from the test DataFrame.\n",
        "if missing_labels:\n",
        "    print(f\"Warning: Missing labels {missing_labels}\")\n",
        "else:\n",
        "    y_true = test_sp[class_labels].values #Extracts ground-truth labels (y_true) for the test split.\n",
        "\n",
        "\n",
        "    if not np.issubdtype(y_true.dtype, np.bool_): #Ensures ground-truth labels are binary (0 or 1).\n",
        "        y_true = (y_true > 0).astype(int)\n",
        "    y_pred = np.array(all_probabilities)\n",
        "\n",
        "    #i have chosen threshold as 0.5 as it is the mid value of 0 and 1, it can be chosen anything\n",
        "    threshold = 0.5\n",
        "    y_pred_binary = (y_pred > threshold).astype(int)  #Converts predicted probabilities (y_pred) into binary predictions using a threshold of 0.5.\n",
        "    y_true_flat = y_true.ravel()  #converting a multi-dimensional array (or a nested structure) into a single-dimensional array (or a flat structure)\n",
        "    y_pred_flat = y_pred_binary.ravel()\n",
        "\n",
        "    accuracy = accuracy_score(y_true_flat, y_pred_flat)  #Accuracy: Fraction of correct predictions.\n",
        "    f1 = f1_score(y_true_flat, y_pred_flat, average=\"macro\") #F1 Score: Harmonic mean of precision and recall.\n",
        "    precision = precision_score(y_true_flat, y_pred_flat, average=\"macro\") #Precision: Fraction of relevant predictions among all positive predictions.\n",
        "    recall = recall_score(y_true_flat, y_pred_flat, average=\"macro\") #Recall: Fraction of true positives among all relevant instances.\n",
        "    #When using average=\"macro\", the metric is computed as the unweighted mean of the metrics calculated for each class individually. This means each class contributes equally, regardless of its size (number of samples).\n",
        "\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-06T14:16:41.664508Z",
          "iopub.status.busy": "2024-11-06T14:16:41.663575Z",
          "iopub.status.idle": "2024-11-06T14:16:42.039437Z",
          "shell.execute_reply": "2024-11-06T14:16:42.038516Z",
          "shell.execute_reply.started": "2024-11-06T14:16:41.664465Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7VEkaKi6Msu",
        "outputId": "1d17b6d7-1a59-49c0-dbd7-7ee8b4b5158d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4916\n",
            "F1 Score (macro): 0.3296\n",
            "Precision (macro): 0.2458\n",
            "Recall (macro): 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "#accuracy for Q.1\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "#finding accuracy\n",
        "#here i have converted the probabailites either to 0 or 1. if probability is >0.5, it is converted to 1 and otherwise converted to 0\n",
        "missing_labels = [label for label in class_labels if label not in test_sp.columns] #Checks if any expected class labels are missing from the test DataFrame.\n",
        "if missing_labels:\n",
        "    print(f\"Warning: Missing labels {missing_labels}\")\n",
        "else:\n",
        "    y_true = test_sp[class_labels].values #Extracts ground-truth labels (y_true) for the test split.\n",
        "\n",
        "\n",
        "    if not np.issubdtype(y_true.dtype, np.bool_): #Ensures ground-truth labels are binary (0 or 1).\n",
        "        y_true = (y_true > 0).astype(int)\n",
        "    y_pred = np.array(all_probabilities)\n",
        "\n",
        "    #i have chosen threshold as 0.5 as it is the mid value of 0 and 1, it can be chosen anything\n",
        "    threshold = 0.5\n",
        "    y_pred_binary = (y_pred > threshold).astype(int)  #Converts predicted probabilities (y_pred) into binary predictions using a threshold of 0.5.\n",
        "    y_true_flat = y_true.ravel()  #converting a multi-dimensional array (or a nested structure) into a single-dimensional array (or a flat structure)\n",
        "    y_pred_flat = y_pred_binary.ravel()\n",
        "\n",
        "    accuracy = accuracy_score(y_true_flat, y_pred_flat)  #Accuracy: Fraction of correct predictions.\n",
        "    f1 = f1_score(y_true_flat, y_pred_flat, average=\"macro\") #F1 Score: Harmonic mean of precision and recall.\n",
        "    precision = precision_score(y_true_flat, y_pred_flat, average=\"macro\") #Precision: Fraction of relevant predictions among all positive predictions.\n",
        "    recall = recall_score(y_true_flat, y_pred_flat, average=\"macro\") #Recall: Fraction of true positives among all relevant instances.\n",
        "    #When using average=\"macro\", the metric is computed as the unweighted mean of the metrics calculated for each class individually. This means each class contributes equally, regardless of its size (number of samples).\n",
        "\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-11-06T14:19:32.612055Z",
          "iopub.status.busy": "2024-11-06T14:19:32.611564Z",
          "iopub.status.idle": "2024-11-06T14:35:20.274103Z",
          "shell.execute_reply": "2024-11-06T14:35:20.272533Z",
          "shell.execute_reply.started": "2024-11-06T14:19:32.611993Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "t-6zPSPw6Msu",
        "outputId": "d1f406f2-06a7-41eb-b247-9a02332cb341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-48-e0416add9d93>:82: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # For mixed precision training\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "<ipython-input-48-e0416add9d93>:98: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-e0416add9d93>\u001b[0m in \u001b[0;36m<cell line: 132>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;31m# Train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-e0416add9d93>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Mixed precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2810\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Q.2\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(\"/content/images_training_rev1.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/images_training_rev1\")\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"/content/training_solutions_rev1_updated.csv\")\n",
        "\n",
        "\n",
        "train_sp, test_sp = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "image_dir = \"/content/images_training_rev1/\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class GalaxyDataset(Dataset):  #Define a PyTorch Dataset to handle the Galaxy Zoo dataset\n",
        "    def __init__(self, dataframe, image_dir, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "        self.image_paths = dataframe['GalaxyID']\n",
        "        self.labels = dataframe.drop(columns=['GalaxyID']).values.astype(np.float32)\n",
        "        self.image_dir = image_dir\n",
        "# Initialize the dataset, including the image directory, labels, and optional transformations.\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "#__len__: Returns the total number of items in the dataset.\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.image_paths.iloc[idx]\n",
        "        img_path = os.path.join(self.image_dir, f\"{img_id}.jpg\")\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = torch.tensor(self.labels[idx])\n",
        "        return image, label\n",
        "#__getitem__: Given an index:\n",
        "# Load the image using PIL.\n",
        "# Apply transformations (resize, normalize, etc.).\n",
        "# Return the image tensor and corresponding label.\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "#creating dataloaders\n",
        "train_dataset = GalaxyDataset(train_sp, image_dir, transform=transform)\n",
        "val_dataset = GalaxyDataset(test_sp, image_dir, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "#batch_size: Number of images per batch.\n",
        "# shuffle: Randomize order for training.\n",
        "# num_workers: Parallel data loading.\n",
        "# pin_memory: Optimizes data transfer to GPU.\n",
        "\n",
        "model = models.resnet50(pretrained=False)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 37)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()   #The loss function measures how far the model's predictions are from the true labels.\n",
        "#BCEWithLogitsLoss\n",
        "# Use: This is used for multi-label binary classification. Each output label is treated as a separate binary classification problem.\n",
        "# What it does: It applies a sigmoid function to the raw logits (unnormalized output) to squeeze them into the range (0, 1) and then computes the binary cross-entropy loss for each label.\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4) #The optimizer is responsible for updating the model's weights to minimize the loss.\n",
        "#Adam Optimizer\n",
        "# Adam (Adaptive Moment Estimation) is an advanced optimization algorithm.\n",
        "# It combines the benefits of:\n",
        "# Momentum: Helps accelerate convergence by taking past gradients into account.\n",
        "# Adaptive Learning Rate: Adjusts the learning rate for each parameter based on the magnitude of past gradients.\n",
        "# Learning Rate (lr=1e-4): Controls the step size for updating the weights. A smaller learning rate ensures stable convergence but may require more epochs to train.\n",
        "\n",
        "scaler = GradScaler()  #The Gradient Scaler is used for mixed-precision training, where some computations are performed in lower precision (e.g., float16) to save memory and speed up training.\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True) #Scheduler: Dynamically adjusts the learning rate to ensure efficient and effective training.\n",
        "\n",
        "def train_model(model, dataloader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        scheduler.step(running_loss / len(dataloader))\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(dataloader):.4f}\")\n",
        "\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
        "            all_predictions.extend(probabilities)\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "    predicted_classes = (all_predictions > 0.5).astype(int)  # Threshold for binary prediction\n",
        "    accuracy = accuracy_score(all_labels.flatten(), predicted_classes.flatten())\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
        "evaluate_model(model, val_loader)\n",
        "\n",
        "#this is my generic code for Q.2, since I waited for about 1.5 hours and still could not see any output, i decided to implement on only 500 images in the next code"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since I waited for about 1.5 hours and still could not see any output, i decided to implement the above code on only 500 images in the next code"
      ],
      "metadata": {
        "id": "ZiuCcz1yJy61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.2\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(\"/content/images_training_rev1.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/images_training_rev1\")\n",
        "\n",
        "data = pd.read_csv(\"/content/training_solutions_rev1_updated.csv\")\n",
        "\n",
        "train_sp, test_sp = data.head(500), data.head(500)\n",
        "\n",
        "\n",
        "image_dir = \"/content/images_training_rev1/\"\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class GalaxyDataset(Dataset):\n",
        "    def __init__(self, dataframe, image_dir, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "        self.image_paths = dataframe['GalaxyID']\n",
        "        self.labels = dataframe.drop(columns=['GalaxyID']).values.astype(np.float32)\n",
        "        self.image_dir = image_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.image_paths.iloc[idx]\n",
        "        img_path = os.path.join(self.image_dir, f\"{img_id}.jpg\")\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = torch.tensor(self.labels[idx])\n",
        "        return image, label\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = GalaxyDataset(train_sp, image_dir, transform=transform)\n",
        "val_dataset = GalaxyDataset(test_sp, image_dir, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "\n",
        "model = models.resnet50(pretrained=False)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 37)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scaler = GradScaler()\n",
        "\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "def train_model(model, dataloader, criterion, optimizer, num_epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        scheduler.step(running_loss / len(dataloader))\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(dataloader):.4f}\")\n",
        "\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
        "            all_predictions.extend(probabilities)\n",
        "            labels_binary = (labels > 0.5).int().cpu().numpy()\n",
        "            all_labels.extend(labels_binary)\n",
        "\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    predicted_classes = (all_predictions > 0.5).astype(int)\n",
        "\n",
        "    all_labels_flat = all_labels.flatten()\n",
        "    predicted_classes_flat = predicted_classes.flatten()\n",
        "\n",
        "    accuracy = accuracy_score(all_labels_flat, predicted_classes_flat)\n",
        "    print(f\"Accuracy: {accuracy*100:.4f}\")\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=3)\n",
        "evaluate_model(model, val_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpA1-3bkwwtR",
        "outputId": "217f69d7-ed10-4604-d591-04bc386c6043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-52-9ffff795202f>:81: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # For mixed precision training\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "<ipython-input-52-9ffff795202f>:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 0.3135\n",
            "Epoch [2/3], Loss: 0.3050\n",
            "Epoch [3/3], Loss: 0.3053\n",
            "Accuracy: 91.6162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.3\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "with zipfile.ZipFile(\"/content/images_training_rev1.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/images_training_rev1\")\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"/content/training_solutions_rev1_updated.csv\")\n",
        "\n",
        "\n",
        "train_sp, test_sp = data.head(500), data.head(500)  # You can adjust this for a larger dataset\n",
        "\n",
        "image_dir = \"/content/images_training_rev1/images_training_rev1\"\n",
        "\n",
        "# LoRA Layer Implementation\n",
        "class LoRALinear(nn.Module):  #This defines a new PyTorch module that inherits from nn.Module. The purpose of this module is to modify and extend the behavior of an existing linear layer by introducing low-rank adaptation.\n",
        "    def __init__(self, original_layer, rank=2):\n",
        "      # #original_layer: A pre-existing linear layer (e.g., nn.Linear) that this module wraps around and adapts.\n",
        "      # rank: The rank of the low-rank matrices used in the LoRA approximation. Smaller values for rank reduce the number of trainable parameters, making the adaptation more efficient.\n",
        "        super(LoRALinear, self).__init__()  #This initializes the base nn.Module class, which is required for any PyTorch module.\n",
        "        self.original_layer = original_layer  # The original_layer is stored as a part of this module. This layer is used in the forward pass to perform the original computation.\n",
        "        self.rank = rank  #This defines the size of the low-rank approximation. Instead of using a full weight matrix, LoRA introduces two smaller matrices (lora_A and lora_B) to approximate changes.\n",
        "        self.lora_A = nn.Parameter(torch.randn(rank, original_layer.in_features) * 0.01)\n",
        "        self.lora_B = nn.Parameter(torch.randn(original_layer.out_features, rank) * 0.01)\n",
        "\n",
        "    def forward(self, x):  #The forward method defines how input x is processed through the LoRALinear layer.\n",
        "        return self.original_layer(x) + (x @ self.lora_A.T @ self.lora_B.T)  #output=original_layer(x)+x⋅Atranspose.Btranspose\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class GalaxyDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "        # Construct the full path for each image based on the GalaxyID\n",
        "        self.image_paths = dataframe['GalaxyID'].apply(lambda x: f\"{image_dir}/{x}.jpg\")\n",
        "        self.labels = dataframe.drop(columns=['GalaxyID']).values.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths.iloc[idx]  # Get the full path of the image\n",
        "\n",
        "        # Check if the image file exists\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"Warning: Image file not found: {img_path}\")\n",
        "            # You could return a default image (e.g., blank or black image) or skip this sample\n",
        "            image = Image.new(\"RGB\", (224, 224))  # A black placeholder image\n",
        "        else:\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = torch.tensor(self.labels[idx])\n",
        "        return image, label\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = GalaxyDataset(train_sp, transform=transform)\n",
        "val_dataset = GalaxyDataset(test_sp, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Load ResNet-50 and apply LoRA to the FC layer\n",
        "model = models.resnet50(pretrained=True)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = LoRALinear(nn.Linear(num_features, 37), rank=2)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if 'lora' not in name:\n",
        "        param.requires_grad = False   #Freezes most pre-trained weights to save computation and focus training on the LoRA parameters.\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
        "scaler = GradScaler()\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "def train_model(model, dataloader, criterion, optimizer, num_epochs=3):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast():  # Mixed precision\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        scheduler.step(running_loss / len(dataloader))\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(dataloader):.4f}\")\n",
        "\n",
        "\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
        "            all_predictions.extend(probabilities)\n",
        "            labels_binary = (labels > 0.5).int().cpu().numpy()\n",
        "            all_labels.extend(labels_binary)\n",
        "\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    predicted_classes = (all_predictions > 0.5).astype(int)\n",
        "\n",
        "    all_labels_flat = all_labels.flatten()\n",
        "    predicted_classes_flat = predicted_classes.flatten()\n",
        "\n",
        "    accuracy = accuracy_score(all_labels_flat, predicted_classes_flat)\n",
        "    print(f\"Accuracy: {accuracy*100:.4f}\")\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=3)\n",
        "evaluate_model(model, val_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC6VHrZmX95P",
        "outputId": "f6eb978e-d18f-4e0b-b2b4-5643d8b324b5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-28-fb9212385132>:100: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "<ipython-input-28-fb9212385132>:111: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 0.5454\n",
            "Epoch [2/3], Loss: 0.3179\n",
            "Epoch [3/3], Loss: 0.3033\n",
            "Accuracy: 92.3622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy for Q.3\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
        "            all_predictions.extend(probabilities)\n",
        "            labels_binary = (labels > 0.5).int().cpu().numpy()\n",
        "            all_labels.extend(labels_binary)\n",
        "\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "    predicted_classes = (all_predictions > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(all_labels.flatten(), predicted_classes.flatten())\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "evaluate_model(model, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGHRqTWWgJCh",
        "outputId": "a3af8069-8475-4da5-bafd-e9a24c928257"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SUMMARY\n",
        "ACCURACY FOR THE THREE DIFFERENT QUESTIONS IS AS FOLLOWS:\n",
        "Q.1)    49.16%\n",
        "Q.2)    91.62%\n",
        "Q.3)    92.36%"
      ],
      "metadata": {
        "id": "hrwm2gkKNQmo"
      }
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "databundleVersionId": 44352,
          "sourceId": 3175,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30787,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}